{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "import pickle\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Flatten, BatchNormalization, Conv1D, MaxPooling1D\n",
    "from keras import Input\n",
    "# from keras.layers import Conv1D, MaxPooling1D\n",
    "\n",
    "from keras.metrics import mean_squared_error\n",
    "import tensorflow as tf\n",
    "\n",
    "with open('./data/floatimg.pkl', 'rb') as f:\n",
    "    df = pickle.load(f)\n",
    "\n",
    "n = 100 # 100일간 데이터 input\n",
    "test_num = 10 # 10일간 데이터 output\n",
    "\n",
    "df_forplot = df[-test_num:]\n",
    "df = df[:-test_num]\n",
    "\n",
    "# ---- Scaling ----\n",
    "\n",
    "scaler = MinMaxScaler()\n",
    "temp_data_scaled = scaler.fit_transform(df['value'].values.reshape(-1, 1))[:, 0]\n",
    "df['value'] = np.float32(temp_data_scaled).reshape(-1, 1)\n",
    "\n",
    "# -----------------\n",
    "\n",
    "data = df.values\n",
    "\n",
    "# 10일 뒤 데이터 예측\n",
    "X = np.array([np.array(data[i:i+n]) for i in range(len(data)-n-test_num+1)])\n",
    "y = np.array([np.array(df['value'].values[i+n+test_num-1]) for i in range(len(data)-n-test_num+1)])\n",
    "\n",
    "# X = X.reshape((-1, n, 1))\n",
    "# y = y.reshape((-1, 10, 1))\n",
    "\n",
    "def plot_result(his):\n",
    "    fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(12, 4))\n",
    "    ax1.plot(his.history['loss'])\n",
    "    ax1.plot(his.history['val_loss'])\n",
    "    ax1.set_title('Model Loss')\n",
    "    ax1.set_ylabel('Loss')\n",
    "    ax1.set_xlabel('Epoch')\n",
    "    ax1.legend(['Train', 'Validation'], loc='upper right')\n",
    "\n",
    "    ax2.plot(his.history['mae'])\n",
    "    ax2.plot(his.history['val_mae'])\n",
    "    ax2.set_title('Model MAE')\n",
    "    ax2.set_ylabel('MAE')\n",
    "    ax2.set_xlabel('Epoch')\n",
    "    ax2.legend(['Train', 'Validation'], loc='upper right')\n",
    "\n",
    "    plt.show()\n",
    "\n",
    "def make_pred(num, model):\n",
    "    data_pred = np.array(df['value'].values[:-n])\n",
    "    for i in range(num):\n",
    "        temp = data_pred[-n:]\n",
    "        pred = model.predict(temp.reshape(1, -1))\n",
    "        data_pred = np.append(data_pred, pred)\n",
    "    return data_pred[-num:]\n",
    "\n",
    "from keras.callbacks import EarlyStopping\n",
    "\n",
    "custom_early_stopping = EarlyStopping(\n",
    "    monitor='val_loss',\n",
    "    patience=10,\n",
    "    restore_best_weights=True\n",
    ")\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(np.array(X), np.array(y), test_size=0.2, random_state=42)\n",
    "\n",
    "mse = tf.keras.losses.MeanSquaredError()\n",
    "mae = tf.keras.losses.MeanAbsoluteError()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('./data/arrayed_img.pkl', 'rb') as f:\n",
    "    df_a = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(512, 512, 1)"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_a.iloc[:, 0][0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((2144, 100, 3), (2144,), (536, 100, 3), (536,))"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape, y_train.shape, X_test.shape, y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " image1_input (InputLayer)      [(None, 512, 512, 1  0           []                               \n",
      "                                )]                                                                \n",
      "                                                                                                  \n",
      " image2_input (InputLayer)      [(None, 512, 512, 1  0           []                               \n",
      "                                )]                                                                \n",
      "                                                                                                  \n",
      " float_input (InputLayer)       [(None, 1)]          0           []                               \n",
      "                                                                                                  \n",
      " image1_cnn (Sequential)        (None, 10)           63397098    ['image1_input[0][0]']           \n",
      "                                                                                                  \n",
      " image2_cnn (Sequential)        (None, 10)           63397098    ['image2_input[0][0]']           \n",
      "                                                                                                  \n",
      " concatenate (Concatenate)      (None, 21)           0           ['float_input[0][0]',            \n",
      "                                                                  'image1_cnn[0][0]',             \n",
      "                                                                  'image2_cnn[0][0]']             \n",
      "                                                                                                  \n",
      " dense_10 (Dense)               (None, 128)          2816        ['concatenate[0][0]']            \n",
      "                                                                                                  \n",
      " dense_11 (Dense)               (None, 64)           8256        ['dense_10[0][0]']               \n",
      "                                                                                                  \n",
      " dense_12 (Dense)               (None, 64)           4160        ['dense_11[0][0]']               \n",
      "                                                                                                  \n",
      " dense_13 (Dense)               (None, 32)           2080        ['dense_12[0][0]']               \n",
      "                                                                                                  \n",
      " final_output (Dense)           (None, 1)            33          ['dense_13[0][0]']               \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 126,811,541\n",
      "Trainable params: 126,809,749\n",
      "Non-trainable params: 1,792\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import Input, Conv2D, Flatten, Dense, Concatenate, MaxPool2D\n",
    "from tensorflow.keras.models import Model\n",
    "\n",
    "# Parameters\n",
    "image_shape = (512, 512, 1)  # Image dimensions\n",
    "num_float_data = 1           # Number of float data points\n",
    "output_length = 10           # Output length from each image processing CNN\n",
    "\n",
    "# Function to create a CNN model for image processing\n",
    "def create_image_cnn(input_shape, output_length, name):\n",
    "    model_ = Sequential(name=f'{name}_cnn')\n",
    "    model_.add(Conv2D(256, (3, 3), activation='relu', input_shape=input_shape))\n",
    "    model_.add(BatchNormalization())\n",
    "    model_.add(MaxPool2D(pool_size=(2, 2)))\n",
    "\n",
    "    model_.add(Conv2D(128, (3, 3), activation='relu'))\n",
    "    model_.add(BatchNormalization())\n",
    "    model_.add(MaxPool2D(pool_size=(2, 2)))\n",
    "\n",
    "    model_.add(Conv2D(64, (3, 3), activation='relu'))\n",
    "    model_.add(BatchNormalization())\n",
    "    model_.add(MaxPool2D(pool_size=(2, 2)))\n",
    "\n",
    "    model_.add(Flatten())\n",
    "    model_.add(Dense(256, activation='relu'))\n",
    "    model_.add(Dense(128, activation='relu'))\n",
    "    model_.add(Dense(64, activation='relu'))\n",
    "    model_.add(Dense(32, activation='relu'))\n",
    "    model_.add(Dense(output_length, activation='relu'))\n",
    "    return model_\n",
    "\n",
    "# 1. CNNs for Each Image\n",
    "cnn1 = create_image_cnn(image_shape, output_length, 'image1')\n",
    "cnn2 = create_image_cnn(image_shape, output_length, 'image2')\n",
    "\n",
    "# 2. Inputs\n",
    "float_input = Input(shape=(num_float_data,), name='float_input')\n",
    "image1_input = Input(shape=image_shape, name='image1_input')\n",
    "image2_input = Input(shape=image_shape, name='image2_input')\n",
    "\n",
    "# Process each image\n",
    "image1_features = cnn1(image1_input)\n",
    "image2_features = cnn2(image2_input)\n",
    "\n",
    "# Concatenation of Image Features and Float Data\n",
    "concatenated = Concatenate()([float_input, image1_features, image2_features])\n",
    "\n",
    "# 3. 1D CNN for Concatenated Data\n",
    "x = Dense(128, activation='relu')(concatenated)\n",
    "x = Dense(64, activation='relu')(x)\n",
    "x = Dense(64, activation='relu')(x)\n",
    "x = Dense(32, activation='relu')(x)\n",
    "final_output = Dense(1, activation='relu', name='final_output')(x)  # Assuming a single float output\n",
    "\n",
    "# Model\n",
    "model1 = Model(inputs=[float_input, image1_input, image2_input], outputs=final_output)\n",
    "\n",
    "model1.compile(loss='mse', optimizer='adam', metrics=['mae'])\n",
    "\n",
    "model1.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "float_train = X_train[:, :, 0].reshape(-1, 100, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'float'>\n"
     ]
    }
   ],
   "source": [
    "print(type(float_train[0][0][0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2144, 100, 1)"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "float_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(2144):\n",
    "    for j in range(100):\n",
    "        float_train[i][j][0] = np.float32(float_train[i][j][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.25157562, 0.22531512, 0.4590336 , ..., 0.3902311 , 0.7079832 ,\n",
       "       0.33981094], dtype=float32)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# float_train.shape, float_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2144, 100)"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train[:, :, 1].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "numpy.ndarray"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(X_train[:, :, 1][0][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(512, 512, 1)"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train[:, :, 1][0][0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "ff = np.asarray(X_train[:, :, 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "ename": "MemoryError",
     "evalue": "Unable to allocate 100. MiB for an array with shape (51200, 512, 1) and data type float32",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mMemoryError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\User\\Desktop\\ai project\\img_reg.ipynb Cell 17\u001b[0m line \u001b[0;36m<cell line: 1>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/User/Desktop/ai%20project/img_reg.ipynb#Y125sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m fu \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39mconcatenate([np\u001b[39m.\u001b[39mconcatenate([X_train[:, :, \u001b[39m1\u001b[39m][i][j] \u001b[39mfor\u001b[39;00m j \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(\u001b[39m100\u001b[39m)])[np\u001b[39m.\u001b[39mnewaxis, :] \u001b[39mfor\u001b[39;00m i \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(\u001b[39m2144\u001b[39m)])\n",
      "\u001b[1;32mc:\\Users\\User\\Desktop\\ai project\\img_reg.ipynb Cell 17\u001b[0m line \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/User/Desktop/ai%20project/img_reg.ipynb#Y125sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m fu \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39mconcatenate([np\u001b[39m.\u001b[39;49mconcatenate([X_train[:, :, \u001b[39m1\u001b[39;49m][i][j] \u001b[39mfor\u001b[39;49;00m j \u001b[39min\u001b[39;49;00m \u001b[39mrange\u001b[39;49m(\u001b[39m100\u001b[39;49m)])[np\u001b[39m.\u001b[39mnewaxis, :] \u001b[39mfor\u001b[39;00m i \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(\u001b[39m2144\u001b[39m)])\n",
      "File \u001b[1;32m<__array_function__ internals>:180\u001b[0m, in \u001b[0;36mconcatenate\u001b[1;34m(*args, **kwargs)\u001b[0m\n",
      "\u001b[1;31mMemoryError\u001b[0m: Unable to allocate 100. MiB for an array with shape (51200, 512, 1) and data type float32"
     ]
    }
   ],
   "source": [
    "fu = np.concatenate([np.concatenate([X_train[:, :, 1][i][j] for j in range(100)])[np.newaxis, :] for i in range(2144)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "ffuck = np.stack(X_train[:, :, 1], axis=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(100, 2144)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ffuck.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "ar = np.array([[1, 2], [3, 4]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<memory at 0x0000019208302B50>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ar."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "cannot reshape array of size 26214400 into shape (2144,100,512,512,1)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\User\\Desktop\\ai project\\img_reg.ipynb Cell 19\u001b[0m line \u001b[0;36m<cell line: 1>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/User/Desktop/ai%20project/img_reg.ipynb#Y131sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m ffuck_real \u001b[39m=\u001b[39m ffuck\u001b[39m.\u001b[39;49mreshape((\u001b[39m2144\u001b[39;49m, \u001b[39m100\u001b[39;49m, \u001b[39m512\u001b[39;49m, \u001b[39m512\u001b[39;49m, \u001b[39m1\u001b[39;49m))\n",
      "\u001b[1;31mValueError\u001b[0m: cannot reshape array of size 26214400 into shape (2144,100,512,512,1)"
     ]
    }
   ],
   "source": [
    "ffuck_real = ffuck.reshape((2144, 100, 512, 512, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fu.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "index 1 is out of bounds for axis 0 with size 1",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\User\\Desktop\\ai project\\img_reg.ipynb Cell 12\u001b[0m line \u001b[0;36m<cell line: 1>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/User/Desktop/ai%20project/img_reg.ipynb#Y114sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m fuck \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39marray([np\u001b[39m.\u001b[39marray([np\u001b[39m.\u001b[39marray([np\u001b[39m.\u001b[39marray([np\u001b[39m.\u001b[39marray([X[:, :, \u001b[39m1\u001b[39m][i][j][k][l][m] \u001b[39mfor\u001b[39;00m m \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(\u001b[39m512\u001b[39m)])\u001b[39mfor\u001b[39;00m l \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(\u001b[39m512\u001b[39m)]) \u001b[39mfor\u001b[39;00m k \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(\u001b[39m1\u001b[39m)]) \u001b[39mfor\u001b[39;00m j \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(\u001b[39m100\u001b[39m)]) \u001b[39mfor\u001b[39;00m i \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(\u001b[39m2144\u001b[39m)])\n",
      "\u001b[1;32mc:\\Users\\User\\Desktop\\ai project\\img_reg.ipynb Cell 12\u001b[0m line \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/User/Desktop/ai%20project/img_reg.ipynb#Y114sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m fuck \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39marray([np\u001b[39m.\u001b[39marray([np\u001b[39m.\u001b[39marray([np\u001b[39m.\u001b[39marray([np\u001b[39m.\u001b[39marray([X[:, :, \u001b[39m1\u001b[39m][i][j][k][l][m] \u001b[39mfor\u001b[39;00m m \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(\u001b[39m512\u001b[39m)])\u001b[39mfor\u001b[39;00m l \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(\u001b[39m512\u001b[39m)]) \u001b[39mfor\u001b[39;00m k \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(\u001b[39m1\u001b[39m)]) \u001b[39mfor\u001b[39;00m j \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(\u001b[39m100\u001b[39m)]) \u001b[39mfor\u001b[39;00m i \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(\u001b[39m2144\u001b[39m)])\n",
      "\u001b[1;32mc:\\Users\\User\\Desktop\\ai project\\img_reg.ipynb Cell 12\u001b[0m line \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/User/Desktop/ai%20project/img_reg.ipynb#Y114sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m fuck \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39marray([np\u001b[39m.\u001b[39marray([np\u001b[39m.\u001b[39marray([np\u001b[39m.\u001b[39marray([np\u001b[39m.\u001b[39marray([X[:, :, \u001b[39m1\u001b[39m][i][j][k][l][m] \u001b[39mfor\u001b[39;00m m \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(\u001b[39m512\u001b[39m)])\u001b[39mfor\u001b[39;00m l \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(\u001b[39m512\u001b[39m)]) \u001b[39mfor\u001b[39;00m k \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(\u001b[39m1\u001b[39m)]) \u001b[39mfor\u001b[39;00m j \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(\u001b[39m100\u001b[39m)]) \u001b[39mfor\u001b[39;00m i \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(\u001b[39m2144\u001b[39m)])\n",
      "\u001b[1;32mc:\\Users\\User\\Desktop\\ai project\\img_reg.ipynb Cell 12\u001b[0m line \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/User/Desktop/ai%20project/img_reg.ipynb#Y114sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m fuck \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39marray([np\u001b[39m.\u001b[39marray([np\u001b[39m.\u001b[39marray([np\u001b[39m.\u001b[39marray([np\u001b[39m.\u001b[39marray([X[:, :, \u001b[39m1\u001b[39m][i][j][k][l][m] \u001b[39mfor\u001b[39;00m m \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(\u001b[39m512\u001b[39m)])\u001b[39mfor\u001b[39;00m l \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(\u001b[39m512\u001b[39m)]) \u001b[39mfor\u001b[39;00m k \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(\u001b[39m1\u001b[39m)]) \u001b[39mfor\u001b[39;00m j \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(\u001b[39m100\u001b[39m)]) \u001b[39mfor\u001b[39;00m i \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(\u001b[39m2144\u001b[39m)])\n",
      "\u001b[1;32mc:\\Users\\User\\Desktop\\ai project\\img_reg.ipynb Cell 12\u001b[0m line \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/User/Desktop/ai%20project/img_reg.ipynb#Y114sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m fuck \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39marray([np\u001b[39m.\u001b[39marray([np\u001b[39m.\u001b[39marray([np\u001b[39m.\u001b[39marray([np\u001b[39m.\u001b[39marray([X[:, :, \u001b[39m1\u001b[39m][i][j][k][l][m] \u001b[39mfor\u001b[39;00m m \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(\u001b[39m512\u001b[39m)])\u001b[39mfor\u001b[39;00m l \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(\u001b[39m512\u001b[39m)]) \u001b[39mfor\u001b[39;00m k \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(\u001b[39m1\u001b[39m)]) \u001b[39mfor\u001b[39;00m j \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(\u001b[39m100\u001b[39m)]) \u001b[39mfor\u001b[39;00m i \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(\u001b[39m2144\u001b[39m)])\n",
      "\u001b[1;32mc:\\Users\\User\\Desktop\\ai project\\img_reg.ipynb Cell 12\u001b[0m line \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/User/Desktop/ai%20project/img_reg.ipynb#Y114sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m fuck \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39marray([np\u001b[39m.\u001b[39marray([np\u001b[39m.\u001b[39marray([np\u001b[39m.\u001b[39marray([np\u001b[39m.\u001b[39marray([X[:, :, \u001b[39m1\u001b[39;49m][i][j][k][l][m] \u001b[39mfor\u001b[39;00m m \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(\u001b[39m512\u001b[39m)])\u001b[39mfor\u001b[39;00m l \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(\u001b[39m512\u001b[39m)]) \u001b[39mfor\u001b[39;00m k \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(\u001b[39m1\u001b[39m)]) \u001b[39mfor\u001b[39;00m j \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(\u001b[39m100\u001b[39m)]) \u001b[39mfor\u001b[39;00m i \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(\u001b[39m2144\u001b[39m)])\n",
      "\u001b[1;31mIndexError\u001b[0m: index 1 is out of bounds for axis 0 with size 1"
     ]
    }
   ],
   "source": [
    "fuck = np.array([np.array([np.array([np.array([np.array([X[:, :, 1][i][j][k][l][m] for m in range(512)])for l in range(512)]) for k in range(1)]) for j in range(100)]) for i in range(2144)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2144, 100, 3)"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.array(fuck).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.array([X_train])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2144, 100)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train[:, :, 1].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train[:, :, 1][0][0][10][10][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "img1_train = [[[[[[X_train[:, :, 1][i][j][k][l][m]] for m in range(1)] for l in range(512)] for k in range(512)] for j in range(100)] for i in range(2144)] # (2144, 512, 512, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('./data/img1_train.pkl', 'wb') as f:\n",
    "    pickle.dump(img1_train, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img2_train = [[[[[[X_train[:, :, 2][i][j][k][l][m]] for m in range(1)] for l in range(512)] for k in range(512)] for j in range(100)] for i in range(2144)] # (2144, 512, 512, 1)\n",
    "with open('./data/img2_train.pkl', 'wb') as f:\n",
    "    pickle.dump(img2_train, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2144, 100, 512, 1)"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "img1_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "closing parenthesis ')' does not match opening parenthesis '[' (699834090.py, line 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  Input \u001b[1;32mIn [1]\u001b[1;36m\u001b[0m\n\u001b[1;33m    img2_train = np.array([np.array([[np.float32(X_train[j, :, 2][0][m[i]]) for i in range(len(X_train[j, :, 2][0]))]) for m in range(512)] for j in range(len(X_train))]) # (2144, 512, 512, 1)\u001b[0m\n\u001b[1;37m                                                                                                                     ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m closing parenthesis ')' does not match opening parenthesis '['\n"
     ]
    }
   ],
   "source": [
    "img2_train = np.array([np.array([np.float32(X_train[j, :, 2][0][i]) for i in range(len(X_train[j, :, 2][0]))]) for j in range(len(X_train))]) # (2144, 512, 512, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "img1_train = np.array([[[np.array([np.float32(X_train[j, :, 1][0][m][i]) for i in range(len(X_train[j, :, 1][0]))]) for m in range(512)] for k in range(100)] for j in range(len(X_train))]) # (2144, 512, 512, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "img1_train = np.array([[[np.array([np.float32(X_train[j, :, 1][k][m][i]) for i in range(len(X_train[j, :, 1][k]))]) for m in range(512)] for k in range(100)] for j in range(len(X_train))]) # (2144, 512, 512, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2144,)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train[:, :, 1][:, 10].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2144, 512, 512, 1)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "img1_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# img1_test = np.array([np.array([X_test[j, :, 1][0][i] for i in range(len(X_test[j, :, 1][0]))]) for j in range(len(X_test))]) # (536, 512, 512, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# img2_test = np.array([np.array([X_test[j, :, 2][0][i] for i in range(len(X_test[j, :, 2][0]))]) for j in range(len(X_test))]) # (536, 512, 512, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(img2_train[0][0][0])==np.float32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2144, 512, 512, 1)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "img2_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, j, k in range(2144, 512, 512):\n",
    "    print(type(img1_train[i][j][k]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2144, 100, 1)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "float_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'float'>\n"
     ]
    }
   ],
   "source": [
    "print(type(float_train[0][0][0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "float_train = np.asarray(float_train, dtype=np.float32)\n",
    "img1_train = np.asarray(img1_train, dtype=np.float32)\n",
    "img2_train = np.asarray(img2_train, dtype=np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2144, 512, 512, 1)"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "img2_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Model was constructed with shape (None, 1) for input KerasTensor(type_spec=TensorSpec(shape=(None, 1), dtype=tf.float32, name='float_input'), name='float_input', description=\"created by layer 'float_input'\"), but it was called on an input with incompatible shape (None, 100).\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "in user code:\n\n    File \"c:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\engine\\training.py\", line 1249, in train_function  *\n        return step_function(self, iterator)\n    File \"c:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\engine\\training.py\", line 1233, in step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"c:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\engine\\training.py\", line 1222, in run_step  **\n        outputs = model.train_step(data)\n    File \"c:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\engine\\training.py\", line 1023, in train_step\n        y_pred = self(x, training=True)\n    File \"c:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 70, in error_handler\n        raise e.with_traceback(filtered_tb) from None\n    File \"c:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\engine\\input_spec.py\", line 277, in assert_input_compatibility\n        raise ValueError(\n\n    ValueError: Exception encountered when calling layer 'model_1' (type Functional).\n    \n    Input 0 of layer \"dense_24\" is incompatible with the layer: expected axis -1 of input shape to have value 21, but received input with shape (None, 120)\n    \n    Call arguments received by layer 'model_1' (type Functional):\n      • inputs=('tf.Tensor(shape=(None, 100, 1), dtype=float32)', 'tf.Tensor(shape=(None, 512, 512, 1), dtype=float32)', 'tf.Tensor(shape=(None, 512, 512, 1), dtype=float32)')\n      • training=True\n      • mask=None\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\User\\Desktop\\ai project\\img_reg.ipynb Cell 21\u001b[0m line \u001b[0;36m<cell line: 1>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/User/Desktop/ai%20project/img_reg.ipynb#X32sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m model1\u001b[39m.\u001b[39;49mfit([float_train, img1_train, img2_train], y_train, epochs\u001b[39m=\u001b[39;49m\u001b[39m10\u001b[39;49m, batch_size\u001b[39m=\u001b[39;49m\u001b[39m32\u001b[39;49m, validation_split\u001b[39m=\u001b[39;49m\u001b[39m0.2\u001b[39;49m, callbacks\u001b[39m=\u001b[39;49m[custom_early_stopping], verbose\u001b[39m=\u001b[39;49m\u001b[39m1\u001b[39;49m)\n",
      "File \u001b[1;32mc:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\utils\\traceback_utils.py:70\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     67\u001b[0m     filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n\u001b[0;32m     68\u001b[0m     \u001b[39m# To get the full stack trace, call:\u001b[39;00m\n\u001b[0;32m     69\u001b[0m     \u001b[39m# `tf.debugging.disable_traceback_filtering()`\u001b[39;00m\n\u001b[1;32m---> 70\u001b[0m     \u001b[39mraise\u001b[39;00m e\u001b[39m.\u001b[39mwith_traceback(filtered_tb) \u001b[39mfrom\u001b[39;00m \u001b[39mNone\u001b[39m\n\u001b[0;32m     71\u001b[0m \u001b[39mfinally\u001b[39;00m:\n\u001b[0;32m     72\u001b[0m     \u001b[39mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[1;32m~\\AppData\\Local\\Temp\\__autograph_generated_files4dkcssq.py:15\u001b[0m, in \u001b[0;36mouter_factory.<locals>.inner_factory.<locals>.tf__train_function\u001b[1;34m(iterator)\u001b[0m\n\u001b[0;32m     13\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m     14\u001b[0m     do_return \u001b[39m=\u001b[39m \u001b[39mTrue\u001b[39;00m\n\u001b[1;32m---> 15\u001b[0m     retval_ \u001b[39m=\u001b[39m ag__\u001b[39m.\u001b[39mconverted_call(ag__\u001b[39m.\u001b[39mld(step_function), (ag__\u001b[39m.\u001b[39mld(\u001b[39mself\u001b[39m), ag__\u001b[39m.\u001b[39mld(iterator)), \u001b[39mNone\u001b[39;00m, fscope)\n\u001b[0;32m     16\u001b[0m \u001b[39mexcept\u001b[39;00m:\n\u001b[0;32m     17\u001b[0m     do_return \u001b[39m=\u001b[39m \u001b[39mFalse\u001b[39;00m\n",
      "\u001b[1;31mValueError\u001b[0m: in user code:\n\n    File \"c:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\engine\\training.py\", line 1249, in train_function  *\n        return step_function(self, iterator)\n    File \"c:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\engine\\training.py\", line 1233, in step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"c:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\engine\\training.py\", line 1222, in run_step  **\n        outputs = model.train_step(data)\n    File \"c:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\engine\\training.py\", line 1023, in train_step\n        y_pred = self(x, training=True)\n    File \"c:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 70, in error_handler\n        raise e.with_traceback(filtered_tb) from None\n    File \"c:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\engine\\input_spec.py\", line 277, in assert_input_compatibility\n        raise ValueError(\n\n    ValueError: Exception encountered when calling layer 'model_1' (type Functional).\n    \n    Input 0 of layer \"dense_24\" is incompatible with the layer: expected axis -1 of input shape to have value 21, but received input with shape (None, 120)\n    \n    Call arguments received by layer 'model_1' (type Functional):\n      • inputs=('tf.Tensor(shape=(None, 100, 1), dtype=float32)', 'tf.Tensor(shape=(None, 512, 512, 1), dtype=float32)', 'tf.Tensor(shape=(None, 512, 512, 1), dtype=float32)')\n      • training=True\n      • mask=None\n"
     ]
    }
   ],
   "source": [
    "model1.fit([float_train, img1_train, img2_train], y_train, epochs=10, batch_size=32, validation_split=0.2, callbacks=[custom_early_stopping], verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
